name: recursive_reasoning.skip_trm@TinyRecursiveReasoningModel_ACTV1
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

halt_exploration_prob: 0.1
halt_max_steps: 16

H_cycles: 3
# skips: [1, 2, 4, 8, 16] OOM
skips: [1, 7]


H_layers: 0
L_layers: 2

hidden_size: 216 #512

num_heads: 8  # min(2, hidden_size // 64)
expansion: 4

puzzle_emb_ndim: ${.hidden_size}

pos_encodings: none
forward_dtype: bfloat16

mlp_t: True # use mlp on L instead of transformer
puzzle_emb_len: 16 # if non-zero, its specified to this value
no_ACT_continue: True # No continue ACT loss, only use the sigmoid of the halt which makes much more sense
# output_layers: 0 # number of transformer blocks before LM head (0 = direct to LM head)
output_layers: 2

global_batch_size: 256


sliding_skips: true
